{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "require './final_project_lib'\n",
    "require './metrics.rb'\n",
    "require './transformers.rb'\n",
    "require './decision_trees.rb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# mean\n",
    "def mean x\n",
    "  x.sum(0.0) / x.size\n",
    "end\n",
    "\n",
    "# stdev\n",
    "def stdev x\n",
    "  m = mean(x)\n",
    "  variance = 0.0\n",
    "  x.each{|v| variance += (v - m) ** 2}\n",
    "  Math.sqrt(variance / (x.size.to_f - 1))\n",
    "end\n",
    "\n",
    "def dot x, w\n",
    "  prod = 0\n",
    "  for key in x.keys\n",
    "    if w.has_key?(key)\n",
    "      prod += x[key] * w[key]\n",
    "    end\n",
    "  end\n",
    "  prod\n",
    "end\n",
    "\n",
    "def norm w\n",
    "  Math.sqrt(dot(w, w))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "require 'digest'\n",
    "class DownsampleNegatives\n",
    "  attr_reader :sampling_rate\n",
    "  def initialize sampling_rate\n",
    "    @sampling_rate = sampling_rate\n",
    "  end\n",
    "  \n",
    "  def train dataset; end\n",
    "  \n",
    "  def update_sampling_rate dataset\n",
    "    class_counts = Hash.new\n",
    "    dataset[\"data\"]\n",
    "      .group_by {|e| e[\"label\"] > 0 ? 1 : 0}\n",
    "      .each {|k,v| class_counts[k] = v.size}\n",
    "    @sampling_rate = class_counts[1] / class_counts[0].to_f\n",
    "  end\n",
    "  \n",
    "  def hashprob id\n",
    "    salt = \"eifjcchdivlbreckvgndlvkgdtdjnbcnjldelrgefcgt\"\n",
    "    (Digest::MD5.hexdigest(id.to_s + salt).to_i(16) % 100000).abs / 100000.0\n",
    "  end\n",
    "  \n",
    "  def can_keep? example\n",
    "    can_keep = true\n",
    "    can_keep = if example[\"label\"] > 0\n",
    "      true\n",
    "    elsif hashprob(example[\"id\"]) < @sampling_rate\n",
    "      true\n",
    "    else\n",
    "      false\n",
    "    end\n",
    "    return can_keep\n",
    "  end\n",
    "\n",
    "  def apply(example_batch)\n",
    "    return example_batch.select! {|example| can_keep? example}\n",
    "  end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MinMaxTransformer\n",
    "  attr_reader :mins, :maxs\n",
    "  \n",
    "  def initialize feature_names\n",
    "    @mins = Hash.new\n",
    "    @maxs = Hash.new\n",
    "    @feature_names = feature_names\n",
    "  end\n",
    "  \n",
    "  def train dataset\n",
    "    @feature_names.each do |feature_name|\n",
    "      x = dataset[\"data\"].map{ |r| r[\"features\"][feature_name]}.select{|v| v != nil}\n",
    "      if x.first.kind_of?(String)\n",
    "        next\n",
    "      end\n",
    "      @mins[feature_name] = x.min\n",
    "      @maxs[feature_name] = x.max\n",
    "    end\n",
    "  end\n",
    "  \n",
    "  def apply example_batch\n",
    "    example_batch.each do |example|\n",
    "      @feature_names.each do |feature_name|\n",
    "        val = example[\"features\"][feature_name]\n",
    "        if val == nil ||val.kind_of?(String)\n",
    "          next\n",
    "        end\n",
    "        example[\"features\"][feature_name] = (val - @mins[feature_name]) / (@maxs[feature_name] - @mins[feature_name])\n",
    "      end\n",
    "    end\n",
    "    return example_batch\n",
    "  end\n",
    "end\n",
    "\n",
    "class MeanImputation\n",
    "  attr_reader :means\n",
    "  \n",
    "  def initialize feature_names\n",
    "    @means = Hash.new\n",
    "    @feature_names = feature_names\n",
    "  end\n",
    "  \n",
    "  def train dataset    \n",
    "    # BEGIN YOUR CODE\n",
    "    @feature_names.each do |feature_name|\n",
    "      x = dataset[\"data\"].map{ |r| r[\"features\"][feature_name] }.select{ |v| v != nil}\n",
    "      if !x.first.is_a? Numeric\n",
    "        next\n",
    "      end\n",
    "      @means[feature_name] = mean(x)\n",
    "    end\n",
    "    #END YOUR CODE\n",
    "  end\n",
    "  \n",
    "  def apply(example_batch)\n",
    "    # BEGIN YOUR CODE\n",
    "     example_batch.each do |example|\n",
    "      @feature_names.each do |feature_name|\n",
    "        if example[\"features\"][feature_name] == nil\n",
    "          example[\"features\"][feature_name] = @means[feature_name]\n",
    "        end\n",
    "      end\n",
    "    end\n",
    "    #END YOUR CODE\n",
    "    return example_batch\n",
    "  end\n",
    "end\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FeatureTransformPipeline\n",
    "  def initialize *transformers\n",
    "    @transformers = transformers\n",
    "  end\n",
    "  \n",
    "  def train dataset\n",
    "    @transformers.each{|transform| transform.train(dataset)}\n",
    "  end\n",
    "  \n",
    "  def apply example_batch \n",
    "    return @transformers.inject(example_batch) do |u, transform|\n",
    "      \n",
    "      u = transform.apply example_batch\n",
    "     \n",
    "    end\n",
    "    \n",
    "    example_batch  \n",
    "  end\n",
    "end\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  class AUCMetric\n",
    "module Metric\n",
    "  def apply scores\n",
    "  end\n",
    "end\n",
    "\n",
    "class AUCMetric \n",
    "  include Metric\n",
    "  \n",
    "  def roc_curve(scores)\n",
    "    fp_rates = [0.0]\n",
    "    tp_rates = [0.0]\n",
    "    auc = 0.0\n",
    "    \n",
    "    np = scores.inject(0.0) {|u,s| u += s.last}\n",
    "    nn = scores.inject(0.0) {|u,s| u += (1 - s.last)}\n",
    "    \n",
    "    ni_p = 0\n",
    "    ni_n = 0\n",
    "    scores.sort_by {|s| -s.first}.each do |s|\n",
    "      ni_n += 1 if s.last <= 0\n",
    "      ni_p += 1 if s.last > 0  \n",
    "      fpr = ni_n / nn\n",
    "      tpr = ni_p / np\n",
    "      auc += 0.5 * (tpr + tp_rates.last) * (fpr - fp_rates.last)\n",
    "      fp_rates.append(fpr)\n",
    "      tp_rates.append(tpr)\n",
    "    end\n",
    "    \n",
    "    return [fp_rates, tp_rates, auc]\n",
    "  end\n",
    "  \n",
    "  def apply scores\n",
    "    fp, tp, auc = roc_curve scores\n",
    "    auc\n",
    "  end\n",
    "end\n",
    "\n",
    "# cross_validate\n",
    "def cross_validate dataset, folds, &block\n",
    "  examples = dataset[\"data\"]\n",
    "  fold_size = examples.size / folds\n",
    "  folds.times do |fold|\n",
    "    ##CV training examples\n",
    "    train_data = dataset.clone\n",
    "    train_data[\"data\"] = train_data[\"data\"][0, fold * fold_size] + train_data[\"data\"][((fold + 1) * fold_size)..-1]\n",
    "    \n",
    "     ##CV testing examples\n",
    "    test_data = dataset.clone\n",
    "    test_data[\"data\"] = test_data[\"data\"][fold * fold_size, fold_size]             \n",
    "\n",
    "    ## Call the callback like this:\n",
    "    yield train_data, test_data, fold\n",
    "  end\n",
    "end\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def class_distribution dataset\n",
    "  # BEGIN YOUR CODE\n",
    "  res = Hash.new(0.0)\n",
    "  dataset.each do |row|\n",
    "    res[row[\"label\"]] += 1\n",
    "  end\n",
    "  total = res.each_value.sum(0.0)\n",
    "  res.each_key do |c|\n",
    "    res[c] /= total\n",
    "  end\n",
    "  return res\n",
    "  #END YOUR CODE\n",
    "end\n",
    "\n",
    "def entropy dist\n",
    "  # BEGIN YOUR CODE\n",
    "  entropy = 0.0\n",
    "  dist.each_value do |v|\n",
    "    if v == 0\n",
    "      return 0.0\n",
    "    end\n",
    "    entropy -= v * Math.log(v)\n",
    "  end\n",
    "  return entropy\n",
    "  #END YOUR CODE\n",
    "end\n",
    "\n",
    "def information_gain h0, splits\n",
    "  # BEGIN YOUR CODE\n",
    "  info_gain = h0\n",
    "  total_size = splits.values.map { |s| s.size }.sum(0.0)\n",
    "  splits.each_key do |k|\n",
    "    h = entropy(class_distribution(splits[k]))\n",
    "    n = splits[k].size\n",
    "    info_gain -= n / total_size * h\n",
    "  end\n",
    "  return info_gain\n",
    "  #END YOUR CODE\n",
    "end\n",
    "\n",
    "def random_features_subset dataset, rng, num_features\n",
    "  feature_list = dataset[\"features\"].sample(num_features, random: rng)  \n",
    "end\n",
    "\n",
    "def random_forest_dataset dataset, rng, num_features\n",
    "  feature_list = random_features_subset dataset, rng, num_features\n",
    "  examples = dataset[\"data\"]\n",
    "  new_dataset = nil\n",
    "  \n",
    "  # BEGIN YOUR CODE\n",
    "  new_dataset = Hash.new\n",
    "  new_dataset[\"features\"] = feature_list\n",
    "  new_dataset[\"data\"] = []\n",
    "\n",
    "  examples.size.times do\n",
    "    example = examples.sample(random:rng)\n",
    "    new_features = example[\"features\"].select {|key, value| feature_list.include?(key)}\n",
    "    new_example = {\"id\" => example[\"id\"], \"features\" => new_features, \"label\" => example[\"label\"]}\n",
    "    new_dataset[\"data\"].append(new_example)\n",
    "  end\n",
    "  #END YOUR CODE\n",
    "  return new_dataset\n",
    "end\n",
    "\n",
    "class CategoricalSplit\n",
    "  attr_reader :feature_name\n",
    "  \n",
    "  def initialize fname\n",
    "    @feature_name = fname\n",
    "    @path_pattern = \"%s == '%s'\"\n",
    "  end\n",
    "  \n",
    "  def to_s\n",
    "    \"Categorical[#{@feature_name}]\"\n",
    "  end\n",
    "\n",
    "  def split_on_feature examples\n",
    "    splits = Hash.new {|h, k| h[k] = Array.new}\n",
    "    \n",
    "    # BEGIN YOUR CODE\n",
    "    examples.each do |example|\n",
    "      feature_value = example[\"features\"][@feature_name]\n",
    "      if feature_value == nil\n",
    "        next\n",
    "      end\n",
    "      split_name = @path_pattern % [@feature_name, feature_value]\n",
    "      splits[split_name].append(example)\n",
    "    end\n",
    "    #END YOUR CODE\n",
    "    \n",
    "    return splits\n",
    "  end\n",
    "\n",
    "  def test example    \n",
    "    # BEGIN YOUR CODE\n",
    "    feature_value = example[\"features\"][@feature_name]\n",
    "    if feature_value == nil\n",
    "      return nil\n",
    "    end\n",
    "    path_name = @path_pattern % [@feature_name, feature_value]\n",
    "    #END YOUR CODE\n",
    "    \n",
    "    return path_name\n",
    "  end\n",
    "end\n",
    "\n",
    "class NumericSplit\n",
    "  attr_reader :feature_name, :split_point, :paths\n",
    "  def initialize fname, value\n",
    "    @feature_name = fname\n",
    "    @split_point = value\n",
    "    @split_point_str = \"%.2g\" % @split_point\n",
    "    @paths = [\"#{@feature_name} < #{@split_point_str}\", \"#{@feature_name} >= #{@split_point_str}\"]\n",
    "  end\n",
    "  \n",
    "  def to_s\n",
    "    \"Numeric[#{@feature_name} <=> #{@split_point_str}]\"\n",
    "  end\n",
    "\n",
    "  def split_on_feature examples\n",
    "    splits = Hash.new { |h, k| h[k] = [] }\n",
    "\n",
    "    # BEGIN YOUR CODE\n",
    "    examples.each do |example|\n",
    "      feature_value = example[\"features\"][@feature_name]\n",
    "      if feature_value == nil\n",
    "        feature_value = 0\n",
    "      end\n",
    "      if feature_value >= @split_point\n",
    "        path = paths[1]\n",
    "      else\n",
    "        path = paths[0]\n",
    "      end\n",
    "      splits[path].append(example)\n",
    "    end\n",
    "    #END YOUR CODE\n",
    "\n",
    "    return splits\n",
    "  end\n",
    "  \n",
    "  def test example\n",
    "    # BEGIN YOUR CODE\n",
    "    feature_value = example[\"features\"][@feature_name]\n",
    "    if feature_value == nil\n",
    "        return nil\n",
    "    end\n",
    "    if feature_value >= @split_point\n",
    "        return paths[1]\n",
    "    else\n",
    "        return paths[0]\n",
    "    end\n",
    "    #END YOUR CODE\n",
    "  end\n",
    "end\n",
    "\n",
    "class CategoricalSplitter\n",
    "  def matches? examples, feature_name\n",
    "    has_feature = examples.select {|r| r[\"features\"].has_key? feature_name} \n",
    "    return false if has_feature.empty?    \n",
    "    return has_feature.all? do |r| \n",
    "      r[\"features\"].fetch(feature_name, 0.0).is_a?(String)\n",
    "    end\n",
    "  end\n",
    "  \n",
    "  def create_split examples, parent_entropy, feature_name\n",
    "    # BEGIN YOUR CODE\n",
    "    if not matches? examples, feature_name\n",
    "      return nil\n",
    "    end\n",
    "    split = CategoricalSplit.new(feature_name)\n",
    "    splits = split.split_on_feature(examples)\n",
    "    ig = information_gain(parent_entropy, splits)\n",
    "    #END YOUR CODE\n",
    "    \n",
    "    return {\"split\" => split, \"information_gain\" => ig}\n",
    "  end\n",
    "end\n",
    "\n",
    "class NumericSplitter\n",
    "  def matches? examples, feature_name\n",
    "    has_feature = examples.select {|r| r[\"features\"].has_key? feature_name} \n",
    "    return false if has_feature.empty?    \n",
    "    return has_feature.all? do |r| \n",
    "      r[\"features\"].fetch(feature_name, 0.0).is_a?(Numeric)\n",
    "    end\n",
    "  end\n",
    "  \n",
    "  def create_split examples, parent_entropy, feature_name    \n",
    "    # BEGIN YOUR CODE\n",
    "    if not matches? examples, feature_name\n",
    "      return nil\n",
    "    end\n",
    "    all_t = examples.collect {|r| r[\"features\"][feature_name] }.filter { |t| t != nil}.uniq.sort\n",
    "    sorted_x = examples.sort_by { |r| r[\"features\"][feature_name] or 0}\n",
    "    best_val = 0\n",
    "    ig_max = 0\n",
    "\n",
    "    left = Hash.new(0.0)\n",
    "    right = Hash.new(0.0)\n",
    "    examples.each do |row|\n",
    "      right[row[\"label\"]] += 1\n",
    "    end\n",
    "\n",
    "    nleft = 0.0\n",
    "    nright = examples.size\n",
    "    n = examples.size\n",
    "    def get_class_distribution c, total\n",
    "      res = Hash.new\n",
    "      c.each do |k, v|\n",
    "        if (v / total) != 0\n",
    "          res[k] = (v / total)\n",
    "        end\n",
    "      end\n",
    "\n",
    "      return res\n",
    "    end\n",
    "\n",
    "    all_t.each do |t|\n",
    "      while sorted_x.first[\"features\"][feature_name] == nil or sorted_x.first[\"features\"][feature_name] < t\n",
    "        row = sorted_x.shift\n",
    "        left[row[\"label\"]] += 1.0\n",
    "        right[row[\"label\"]] -= 1.0\n",
    "        nleft += 1.0\n",
    "        nright -= 1.0\n",
    "      end\n",
    "\n",
    "      cleft = get_class_distribution(left, nleft)\n",
    "      cright = get_class_distribution(right, nright)\n",
    "      ig = parent_entropy - (nleft / n) * entropy(cleft) - (nright / n) * entropy(cright)\n",
    "\n",
    "      if ig > ig_max\n",
    "        best_val = t\n",
    "        ig_max = ig\n",
    "      end\n",
    "    end\n",
    "    ig = ig_max\n",
    "    split = NumericSplit.new feature_name, best_val\n",
    "    #END YOUR CODE\n",
    "    \n",
    "    return {\"split\" => split, \"information_gain\" => ig}\n",
    "  end\n",
    "end\n",
    "\n",
    "class DecisionNode\n",
    "  attr_reader :children, :examples, :split, :node_entropy, :node_class_distribution\n",
    "  \n",
    "  def initialize examples\n",
    "    @examples = examples\n",
    "    @node_class_distribution = class_distribution examples    \n",
    "    @node_entropy = entropy (@node_class_distribution)\n",
    "    @children = Hash.new\n",
    "  end\n",
    "  \n",
    "  def is_leaf?\n",
    "    self.children.empty?\n",
    "  end\n",
    "      \n",
    "  def score positive_class_label\n",
    "    # BEGIN YOUR CODE\n",
    "    return @node_class_distribution[positive_class_label]\n",
    "    #END YOUR CODE\n",
    "  end\n",
    "\n",
    "  def all_possible_splits feature_names, splitters\n",
    "    all_splits = []\n",
    "    \n",
    "    # BEGIN YOUR CODE\n",
    "    feature_names.each do |feature_name|\n",
    "      splitters.each do |spliter|\n",
    "        if not spliter.matches?(@examples, feature_name)\n",
    "          next\n",
    "        end\n",
    "        res = spliter.create_split(@examples, @node_entropy, feature_name)\n",
    "        if res[\"split\"] == nil or res[\"information_gain\"] <= 0\n",
    "          next\n",
    "        end\n",
    "        all_splits.append(res)\n",
    "      end\n",
    "    end\n",
    "    #END YOUR CODE\n",
    "    \n",
    "    return all_splits\n",
    "  end\n",
    "\n",
    "  def split_node! split    \n",
    "    @split = split\n",
    "    # BEGIN YOUR CODE\n",
    "    splits = split.split_on_feature(@examples)\n",
    "    splits.each do |key, value|\n",
    "      @children[key] = DecisionNode.new(value)\n",
    "    end\n",
    "    #END YOUR CODE\n",
    "    \n",
    "    @examples = nil\n",
    "  end\n",
    "end\n",
    "\n",
    "class DecisionTreeLearner\n",
    "  include DecisionTreeHelper\n",
    "  include Learner  \n",
    "  attr_reader :root\n",
    "  attr_accessor :positive_class_label\n",
    "  \n",
    "  def initialize positive_class_label, min_size: 10, max_depth: 50\n",
    "    @splitters = [CategoricalSplitter.new, NumericSplitter.new]\n",
    "    @parameters = {\"min_size\" => min_size, \"max_depth\" => max_depth}\n",
    "    @positive_class_label = positive_class_label\n",
    "  end\n",
    "    \n",
    "  def train dataset\n",
    "    @feature_names = dataset[\"features\"]\n",
    "    examples = dataset[\"data\"]\n",
    "    @root = DecisionNode.new examples\n",
    "    grow_tree @root, @parameters[\"max_depth\"]\n",
    "  end\n",
    "\n",
    "  def grow_tree parent, remaining_depth\n",
    "    # BEGIN YOUR CODE\n",
    "    if remaining_depth == 1 or parent.examples.size <= @parameters[\"min_size\"]\n",
    "      return\n",
    "    end\n",
    "      \n",
    "    all_splits = parent.all_possible_splits(@feature_names, @splitters)\n",
    "    if all_splits.size == 0\n",
    "      return\n",
    "    end\n",
    "      \n",
    "    best_split = all_splits.max_by {|s| s[\"information_gain\"] }\n",
    "    parent.split_node!(best_split[\"split\"])\n",
    "    parent.children.each_value do |node|\n",
    "      grow_tree(node, remaining_depth - 1)\n",
    "    end\n",
    "    #END YOUR CODE\n",
    "  end\n",
    "\n",
    "  def predict example\n",
    "    leaf = find_leaf @root, example\n",
    "    return leaf.score @positive_class_label\n",
    "  end\n",
    "\n",
    "  def evaluate eval_dataset\n",
    "    examples = eval_dataset[\"data\"]\n",
    "    examples.map do |example|\n",
    "      score = predict(example)\n",
    "      label = example[\"label\"] == @positive_class_label ? 1 : 0\n",
    "      [score, label]\n",
    "    end\n",
    "  end\n",
    "\n",
    "  def find_leaf node, example\n",
    "    # BEGIN YOUR CODE\n",
    "    if node.is_leaf?\n",
    "      return node\n",
    "    end\n",
    "      \n",
    "    path_name = node.split.test(example)\n",
    "    if node.children[path_name] == nil\n",
    "      return node\n",
    "    end\n",
    "      \n",
    "    return find_leaf(node.children[path_name], example)\n",
    "    #END YOUR CODE\n",
    "  end\n",
    "end\n",
    "\n",
    "class RandomForestLearner\n",
    "  include Learner  \n",
    "  attr_reader :trees\n",
    "  attr_accessor :positive_class_label\n",
    "  attr_accessor :num_features\n",
    "  \n",
    "  def initialize positive_class_label, num_trees: 10, min_size: 10, max_depth: 50, num_features: 3\n",
    "    @parameters = {\"num_trees\" => num_trees, \"min_size\" => min_size, \"max_depth\" => max_depth}\n",
    "    @positive_class_label = positive_class_label\n",
    "    @num_features = num_features\n",
    "    tree_parameters = @parameters.clone.delete :num_trees\n",
    "    \n",
    "    @trees = Array.new(num_trees) do |i| \n",
    "      DecisionTreeLearner.new @positive_class_label, min_size: min_size, max_depth: max_depth\n",
    "    end\n",
    "  end\n",
    "  \n",
    "  def to_s\n",
    "    JSON.pretty_generate(@trees.collect {|t| t.summarize_node t.root})\n",
    "  end\n",
    "  \n",
    "  def train dataset\n",
    "    rng = Random.new SEED\n",
    "    \n",
    "    # BEGIN YOUR CODE\n",
    "    @trees.each do |tree|\n",
    "      random_dataset = random_forest_dataset(dataset, rng, @num_features)\n",
    "      tree.train(random_dataset)\n",
    "    end\n",
    "    #END YOUR CODE\n",
    "  end\n",
    "\n",
    "  def evaluate eval_dataset\n",
    "    examples = eval_dataset[\"data\"]\n",
    "    examples.map do |example|\n",
    "      score = predict(example)\n",
    "      label = example[\"label\"] == @positive_class_label ? 1 : 0\n",
    "      [score, label]\n",
    "    end\n",
    "  end\n",
    "  \n",
    "  def predict example\n",
    "    # BEGIN YOUR CODE\n",
    "    res = 0.0\n",
    "    @trees.each do |tree|\n",
    "      res += tree.predict(example) / @parameters[\"num_trees\"]\n",
    "    end\n",
    "    return res\n",
    "    #END YOUR CODE\n",
    "  end\n",
    "end\n",
    "#END YOUR CODE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ClassifierFive\n",
    "  include FinalProjectClassifier\n",
    "  \n",
    "  def divide numerator, denominator\n",
    "    if numerator.to_i.zero? or denominator.to_i.zero?\n",
    "      return nil\n",
    "    end\n",
    "    \n",
    "    if numerator.to_i.zero? or denominator.to_i.zero?\n",
    "      return nil\n",
    "    end\n",
    "\n",
    "    return numerator.abs() / denominator.to_f\n",
    "  end\n",
    "  \n",
    "  def multiply a, b\n",
    "    if a.to_i.zero? or b.to_i.zero?\n",
    "      return nil\n",
    "    end\n",
    "    \n",
    "    return a.to_f * b.to_f\n",
    "  end\n",
    "  \n",
    "  def create_training_dataset training_db\n",
    "    \n",
    "    features_1 = \"application_train.SK_ID_CURR, application_train.TARGET, \"\n",
    "    features_1 += \"application_train.EXT_SOURCE_1, application_train.EXT_SOURCE_2, application_train.EXT_SOURCE_3, application_train.AMT_CREDIT, application_train.AMT_ANNUITY, application_train.DAYS_BIRTH, application_train.DAYS_EMPLOYED, application_train.AMT_INCOME_TOTAL, \"\n",
    "    features_1 += \"t1.AMT_PAYMENT_MIN_SUM\"\n",
    "    \n",
    "    sql_1 = \"SELECT t.SK_ID_CURR, SUM(t.AMT_PAYMENT_MIN) as AMT_PAYMENT_MIN_SUM FROM \"\n",
    "    sql_1 += \"(SELECT SK_ID_CURR, SK_ID_PREV, MIN(AMT_PAYMENT) as AMT_PAYMENT_MIN FROM installments_payments GROUP BY SK_ID_PREV ORDER BY SK_ID_CURR, SK_ID_PREV) t \"\n",
    "    sql_1 += \"GROUP BY SK_ID_CURR ORDER BY SK_ID_CURR\"\n",
    "    \n",
    "    sql = \"SELECT %s FROM application_train LEFT JOIN (%s) t1 ON application_train.SK_ID_CURR = t1.SK_ID_CURR\" % [features_1, sql_1]\n",
    "    \n",
    "    dataset = create_dataset training_db, sql\n",
    "    dataset[\"data\"].map {|x| x[\"bias\"] = 1.0}\n",
    "    \n",
    "    dataset[\"features\"] += [\"credit_term\", \"annuity_income_percent\", \"credit_income_percent\", \"days_employed_percent\"]\n",
    "    \n",
    "    day_max = 365243 # outlier\n",
    "    \n",
    "    for i in 0..(dataset[\"data\"].size - 1)\n",
    "      example_features = dataset[\"data\"][i][\"features\"]\n",
    "      dataset[\"data\"][i][\"features\"][\"credit_term\"] = divide(example_features[\"amt_annuity\"], example_features[\"amt_credit\"])\n",
    "      dataset[\"data\"][i][\"features\"][\"annuity_income_percent\"] = divide(example_features[\"amt_annuity\"], example_features[\"amt_income_total\"])\n",
    "      dataset[\"data\"][i][\"features\"][\"credit_income_percent\"] = divide(example_features[\"amt_credit\"], example_features[\"amt_income_total\"])\n",
    "      \n",
    "      dataset[\"data\"][i][\"features\"][\"days_birth\"] = divide(example_features[\"days_birth\"], 365)\n",
    "      \n",
    "      if example_features[\"days_employed\"] == day_max\n",
    "        example_features[\"days_employed\"] = nil\n",
    "      end\n",
    "      dataset[\"data\"][i][\"features\"][\"days_employed\"] = divide(example_features[\"days_employed\"], 365)\n",
    "      dataset[\"data\"][i][\"features\"][\"days_employed_percent\"] = divide(example_features[\"days_employed\"], example_features[\"days_birth\"])\n",
    "      \n",
    "    end\n",
    "\n",
    "    return dataset\n",
    "  end \n",
    "  \n",
    "  \n",
    "  def create_evaluation_dataset evaluation_db\n",
    "    return create_training_dataset evaluation_db\n",
    "  end\n",
    "  \n",
    "  def create_learners dataset\n",
    "    dt = RandomForestLearner.new 1, num_trees: 120, min_size: 100, max_depth: 10, num_features: 4\n",
    "    dataset[\"data\"] = dataset[\"data\"][0, 35000]\n",
    "\n",
    "    ds = DownsampleNegatives.new(0.25)\n",
    "    dataset[\"data\"] = ds.apply(dataset[\"data\"])\n",
    "    \n",
    "    transformer = FeatureTransformPipeline.new(\n",
    "      \n",
    "      MeanImputation.new(%w(ext_source_1 ext_source_2 ext_source_3 days_birth days_employed amt_credit amt_annuity credit_term amt_payment_min_sum amt_income_total annuity_income_percent credit_income_percent days_employed_percent)) \n",
    "    )\n",
    "  \n",
    "    learner = CopyingTransformingLearner.new(transformer, dt)  \n",
    "    learner.name = \"Random_Forest\"\n",
    "    learners = [learner]\n",
    "    \n",
    "    return learners\n",
    "  end\n",
    "  \n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_86e342(test_data)\n",
    "  test_basics test_data\n",
    "end\n",
    "\n",
    "test_data_86e342 = {classifier: ClassifierFive.new, min_auc: 0.75, max_auc: 1.0, folds: 5}\n",
    "test_86e342(test_data_86e342)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_7ac09d(test_data)\n",
    "  run_cross_validation_performance test_data\n",
    "  test_data[:cross_validation_results]\n",
    "end\n",
    "test_7ac09d(test_data_86e342)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_994a073(test_data)\n",
    "  test_cross_validation_performance test_data\n",
    "end\n",
    "test_994a073(test_data_86e342)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_f77e97(test_data)\n",
    "  test_data[:db] = dev_db()\n",
    "  test_data[:db_size] = 15334\n",
    "  test_data[:name] = \"dev_eval\"\n",
    "  test_evaluation_set_performance test_data\n",
    "end\n",
    "test_f77e97(test_data_86e342)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Ruby 2.7.1",
   "language": "ruby",
   "name": "ruby"
  },
  "language_info": {
   "file_extension": ".rb",
   "mimetype": "application/x-ruby",
   "name": "ruby",
   "version": "2.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
